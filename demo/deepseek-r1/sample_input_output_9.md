### Sample 9

Input:

```
Please find models created in April 2025 and using CNN.
```

Output:

```
<think>
Okay, so I'm trying to figure out how to find models created in April 2025 that use CNN (Convolutional Neural Networks). The user provided some search results from three different models. Let me go through each model step by step to understand what they are about and see if any of them use CNNs.

First, looking at Model #1: It's called Generative-Fashion-MNIST_latent_new_conditional_model. It was created on April 9, 2025, and last modified in March 2025. The framework is PyTorch 2.7, and the architecture is ConditionalDenoiseDiffusion. From what I know, denoising diffusion models typically involve processes where noise is gradually removed step by step. The description says it's an autoencoder used for conditional generation on the Fashion MNIST dataset. They mentioned using Encoder, Decoder, UNetAttentionBlock, etc., so there are some U-Net elements here. U-Nets do use CNNs in their encoder and decoder parts, which process spatial information through convolutional layers.

Next, Model #2: Generative-Fashion-MNIST_latent_new_model. Created on April 9, 2025, last modified March 2025. Also PyTorch 2.7, architecture is CIFARUNetDenoiser. The description mentions using a novel denoising network with linear attention to reduce computational complexity. They inherit modules like DoubleConv, Down, Up, etc. I know that U-Nets are built with CNN-based encoder and decoder blocks, so this model likely uses CNNs as well.

Model #3: It's for CIFAR10-CatDog dataset. Created on April 9, 2025, last modified March 2025. The architecture is called CIFARUNetDenoiser. They mention using modules like DoubleConv, which I believe are part of the U-Net structure. So again, this model probably uses CNNs in its encoder and decoder parts.

So all three models seem to involve CNNs since they use components like Encoder, Decoder, UNet blocks, DoubleConv, etc., which are all CNN-based architectures.
</think>

All three models provided use Convolutional Neural Networks (CNNs) as part of their architecture. Here's a breakdown:

1. **Model #1**: Uses U-Net architecture with ConditionalDenoiseDiffusion. The Encoder and Decoder components involve CNN layers, specifically the DoubleConv module used in the UNet block.

2. **Model #2**: Based on the U-Net framework (CIFARUNetDenoiser) which includes modules like DoubleConv, Down, Up, etc., indicating the use of CNNs for feature extraction and reconstruction.

3. **Model #3**: Also based on U-Net with the CIFARUNetDenoiser architecture, employing CNN layers such as DoubleConv in its encoder-decoder structure.

Each model leverages CNN components to process spatial information through convolutional layers, essential for their respective tasks of image generation and denoising.

Retrieving and displaying reranked search results:

+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
| Rank | Model ID        | Similarity Score | Similarity Distance |   Size | Created    | Modified   | Path            | Description          | Framework | Arch       | Dataset    | Batch | LR   | Optimizer | Epochs | HW  |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  1   | Generative-     |              N/A |               0.450 | 47.7KB | 2025-04-09 | 2025-03-17 | /Users/yi-nungy | The objective of     | PyTorch 2 | Conditiona | Fashion    | 256   | 1e-0 | Adam      | 100    | CPU |
|      | Fashion-MNIST_l |                  |                     |        |            |            | eh/PyCharmMiscP | this autoencoder is  |           | lDenoiseDi | MNIST      |       | 3    |           |        |     |
|      | atent_new_condi |                  |                     |        |            |            | roject/Generati | to learn and         |           | ffusion    |            |       |      |           |        |     |
|      | tional_model    |                  |                     |        |            |            | ve-Fashion-MNIS | reconstruct images   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | T/latent_new_co | from the Fashion     |           | The        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | nditional_model | MNIST dataset with   |           | codebase   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | .py             | class conditioning.  |           | is impleme |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 2. **Data Pipeline   |           | nting a co |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and Preprocessing**  |           | nditional  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - The data is     |           | denoising  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | loaded from Fashion  |           | diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | MNIST dataset        |           | autoencode |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | located in '/fashion |           | r for      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | _mnist\_conditional' |           | Fashion    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | directory.           |           | MNIST      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Evaluation and     |           | dataset.   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Testing              |           | The archit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Methodology**        |           | ecture     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - The training    |           | comprises  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | progress is          |           | several    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualized using     |           | modules    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | matplotlib with loss |           | like       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | curves and metric    |           | Encoder,   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | tracking plots.      |           | Decoder, U |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | After each epoch,    |           | NetAttenti |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | autoencoder          |           | onBlock,   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generates samples    |           | etc., and  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from pure noise,     |           | uses Condi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditioned on a     |           | tionalUNet |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | target class, and    |           | and Condit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | compares them to     |           | ionalDenoi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | original images in   |           | seDiffusio |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the dataset to       |           | n classes. |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | calculate model      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance metrics  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | such as accuracy and |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruction       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | error. After         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | completion of        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training, t-SNE is   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | used to visualize    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the latent space of  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the autoencoder and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generate GIF         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | animations showing   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the diffusion        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | process with         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different target     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classes.             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Reproduction and   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Extension Guide**    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - To reproduce    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | this model, one      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | should have PyTorch  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | installed and        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | configured with it   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in their             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | environment. Fashion |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | MNIST dataset needs  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | to be available at ' |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | /fashion_mnist\_cond |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | itional' directory   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as mentioned in the  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | code. The provided   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | code can serve as a  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | starting point for   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | further extensions   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | or improvements such |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as changing          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture, using  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different loss       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | functions, exploring |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | other datasets, or   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | adjusting            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters. -   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | All numerical        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | parameters and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | configurations are   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | accurately           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transcribed with no  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | missing information. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | - Training and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | evaluation           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | procedures are       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | completely and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | correctly documented |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for both unet and Co |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | nditionalDenoiseDiff |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | usion models. - This |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | documentation can    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | serve as a starting  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | point for a junior   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | engineer to          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reproduce this model |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | with no further      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | guidance needed,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | assuming they have   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | access to necessary  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | resources (PyTorch   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and Fashion MNIST    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset).            |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  2   | Generative-     |              N/A |               0.461 | 43.4KB | 2025-04-09 | 2025-03-16 | /Users/yi-nungy | This system aims to  | PyTorch 2 | Autoencode | Fashion    | 256   | 1e-0 | Adam      | 1000   | GPU |
|      | Fashion-MNIST_l |                  |                     |        |            |            | eh/PyCharmMiscP | tackle the Fashion   |           | r with     | MNIST      |       | 3    |           |        |     |
|      | atent_new_model |                  |                     |        |            |            | roject/Generati | MNIST dataset's      |           | Denoising  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | ve-Fashion-MNIS | limitations by       |           | Diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | T/latent_new_mo | providing a larger   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | del.py          | variety of styles in |           | The        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generated images, as |           | codebase   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | well as visualizing  |           | features a |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and capturing the    |           | SimpleAuto |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | underlying latent    |           | encoder    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | space structure. The |           | class,     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset used is      |           | which is   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | FashionMNIST, stored |           | an autoenc |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | locally at           |           | oder that  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | '/Users/yi-nungyeh/P |           | denoise    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | yCharmMiscProject/Ge |           | input data |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | nerative-Fashion-MNI |           | using a    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ST/fashion_mnist_res |           | diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ults'. The           |           | process. A |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | preprocessing        |           | dditionall |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | pipeline includes    |           | y, there's |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | data augmentation    |           | also a Sim |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | techniques like      |           | pleDenoise |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | rotation, horizontal |           | Diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | flip, and            |           | and UNetRe |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | normalization. It    |           | sidualBloc |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | consists of          |           | k classes  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Convolutional Neural |           | within the |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Networks (CNN)       |           | codebase.  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | layers, followed by  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | a fully connected    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | layer with the       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | output size equal to |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the desired latent   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dimension. The       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model's ability to   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | capture diverse      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | styles of Fashion    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | MNIST images and     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruct clean,   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | high-quality data    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from pure noise are  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | key evaluation       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | metrics. 2.          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Visualizations like  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | image interpolation  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | between two random   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | samples in the       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | latent space (t-SNE) |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and tracking         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | progress during      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training epochs help |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | assess whether the   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | autoencoder is       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning meaningful  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | features for style   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transfer. During     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model training,      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualization of     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | both the denoising   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | process and the      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | corresponding path   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in latent space are  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | captured through     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | TensorBoard or       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Matplotlib plotting  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | commands to ensure   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visual insights into |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | how the model learns |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | over time. The       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | trained model's      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance on       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Fashion MNIST        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | datasets is          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | evaluated by         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generating new       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | images based on      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learned styles using |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the autoencoder,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | which can be         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualized via       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | matplotlib and saved |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as test set results  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in the 'fashion_mnis |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | t_results/images'    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | folder.              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Reproduction and   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Extension Guide**    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 1. To reproduce this |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model script, ensure |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | that you have        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | installed all        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | necessary libraries, |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | including PyTorch    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (with GPU support if |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | available),          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | torchvision for      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset loading, and |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | matplotlib or other  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | plotting libraries   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for visualization.   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | For extension,       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | consider             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | experimenting with   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architectures,       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning rate        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | schedules,           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | optimization         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | strategies, and      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | regularization       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | techniques.          |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  3   | Generative-     |              N/A |               0.868 | 35.9KB | 2025-04-09 | 2025-03-13 | /Users/yi-nungy | Model Script         | PyTorch 2 | CIFARUNetD | CIFAR10Cat | 64    | 1e-0 | AdamW     | 140    | CPU |
|      | CIFAR-10-Cat-Do |                  |                     |        |            |            | eh/PyCharmMiscP | Documentation: Cat   |           | enoiser    | Dog        |       | 4    |           |        |     |
|      | g_tf_new_patch_ |                  |                     |        |            |            | roject/Generati | Dog Image            |           |            |            |       |      |           |        |     |
|      | 4               |                  |                     |        |            |            | ve-             | Classification with  |           | The 'CIFAR |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | CIFAR-10-Cat-Do | CIFARUNetDenoiser    |           | UNetDenois |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | g/tf_new_patch_ | and Linear Attention |           | er' class  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | 4.py            | Module               |           | is derived |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ==================== |           | from       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ==================== |           | Module,    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ==================== |           | and it     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ==================== |           | consists   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ==================== |           | of several |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | =======              |           | modules    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           | such as Do |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Purpose and        |           | ubleConv,  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Overview**           |           | Down, Up,  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           | PatchExpan |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | This Python ML       |           | d,         |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training             |           | PatchConv, |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model_script, with   |           | ResBlock,  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the help of PyTorch, |           | and SelfAt |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | is a deep learning   |           | tention.   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture for     |           | This archi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classifying images   |           | tecture    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as either cat or dog |           | uses a     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in the               |           | linear     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFAR10-CatDog       |           | attention  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset. It uses a   |           | mechanism  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | novel denoising      |           | with O(n)  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | network called       |           | complexity |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFARUNetDenoiser    |           | instead of |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | that leverages       |           | O(n²),     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | linear attention to  |           | making it  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | improve efficiency   |           | suitable   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | by reducing          |           | for        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | computational        |           | denoising  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | complexity from      |           | images.    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | quadratic to linear. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The data is then     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transformed through  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | various              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | augmentations        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | including random     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | cropping, horizontal |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | flipping, and color  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | distortion for       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | improved model       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generalization.      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | DoubleConv extends   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Module,              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | incorporating a      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | self-attention       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | mechanism to reduce  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | computational        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | complexity in the    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | network.             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFARUNetDenoiser    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | inherits from        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Module, using image  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | size, input          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | channels, output     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classes, patch size, |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and time_dim as      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters. Up  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | layer builds upon    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the Module base      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | class to create a    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | more complex         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | suitable for         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | upscaling features.  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Down layer           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | downsamples image    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | resolution using     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | PyTorch's built-in   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 'Down' module that   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | implements max       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | pooling and stride   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | convolution          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | together. The model  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | used for             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classification is a  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | custom-built         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFARUNetDenoiser    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | incorporating all    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | previously described |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | layers. For each     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | evaluation, the      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | output images are    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualized for       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | qualitative analysis |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | to assess denoising  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | effectiveness and    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classification       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | accuracy.            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Visualization and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Output Artifacts**   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The script utilizes  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | matplotlib's pyplot  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | module for image     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualization, while |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the                  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFARUNetDenoiser    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | produces output      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | artifacts in the     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | form of visually     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | denoised images.     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | After each epoch, a  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | series of sample     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualized outputs   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | is stored, providing |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | an opportunity to    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | monitor model        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | progress and         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance trends.  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | With access to the   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | complete source code |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for reference and    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | using Python 3.7 or  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | newer (compatible    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | with PyTorch 1.7), a |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | junior engineer      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | should be able to    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reproduce this       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | entire architecture  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and extend it        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | further by           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | experimenting with   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | data augmentation    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | techniques, and      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | various attention    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | models.              |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+

```
