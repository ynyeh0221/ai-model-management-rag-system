### Sample 8

Input:

```
Show me models using autoencoder but not trained on MNIST dataset.
```

Output:

```
<think>
Okay, so I need to find models that use autoencoders but aren't trained on the MNIST dataset. Let me look through the search results provided.

First up is Model #1: Generative-CIFAR-10-Cat-Dog_latent_autoencoder_new_structure. The architecture is ConditionalUNet, and it's trained on the CIFAR-10 Cat Dog dataset. That definitely isn't MNIST, so this fits the criteria. It uses a custom time and class embedding system with attention blocks to condition both the diffusion process and the autoencoder reconstruction.

Next is Model #2: Generative-CIFAR-10-Cat-Dog_latent_autoencoder_new_structure_vae. This one's architecture is ConditionalDenoiseDiffusion, which I think combines elements of diffusion models with VAEs or maybe something else. It uses UNet attention blocks and other modules like SwitchSequential. Again, the dataset is CIFAR-10 Cat Dog, so not MNIST.

Model #3: EncoderDecoder_scriptRNN_LSTM has an architecture called EncoderDecoderModel, which sounds more like a traditional encoder-decoder setup used for tasks like machine translation or text generation. It uses PyTorch 2.7 and is trained on a MathDataset instead of MNIST. The dataset here isn't MNIST either.

Wait, are there any other models? Let me check again. Only three models are listed. Models 1 and 2 use CIFAR-10 datasets, which I know aren't MNIST, so they're both good candidates. Model 3 uses MathDataset, definitely not MNIST. So all three meet the criteria of using autoencoders but on different datasets.

I should make sure that each model indeed uses an autoencoder and isn't just a VAE or another variant. Model #1 is a ConditionalUNet, which is more like a denoising autoencoder with conditioning. Model #2 seems to be a diffusion-based approach combined with some VAE-like training since it mentions noise prediction loss computation. Model #3 uses an RNN and LSTM in an encoder-decoder setup, which can also be seen as an autoencoder variant for sequence data.

So all three models should be included in the answer. I need to present each one clearly, mentioning their architectures, datasets, and why they aren't MNIST.
</think>

Based on the search results, here are three models that use autoencoders but are not trained on the MNIST dataset:

### Model 1: ConditionalUNet for CIFAR-10 Cat Dog Dataset
- **Architecture**: ConditionalUNet with custom time and class embeddings.
- **Dataset**: CIFAR-10 Cat Dog.
- **Training**: Trained using a denoising approach conditioned on both diffusion steps and class labels.

### Model 2: ConditionalDenoiseDiffusion for CIFAR-10 Cat Dog Dataset
- **Architecture**: ConditionalDenoiseDiffusion combining UNet attention with other layers.
- **Dataset**: CIFAR-10 Cat Dog.
- **Training**: Diffusion-based training with conditioning on class and time embeddings.

### Model 3: EncoderDecoderModel for MathDataset
- **Architecture**: Encoder-Decoder setup using RNN and LSTM.
- **Dataset**: MathExpressions.
- **Training**: Trained as an encoder-decoder model suitable for arithmetic tasks without MNIST.

These models utilize autoencoder variants on datasets distinct from MNIST, focusing on image generation (CIFAR-10), diffusion processes, and text-based arithmetic prediction.

Retrieving and displaying reranked search results:

+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
| Rank | Model ID        | Similarity Score | Similarity Distance |   Size | Created    | Modified   | Path            | Description          | Framework | Arch       | Dataset    | Batch | LR   | Optimizer | Epochs | HW  |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  1   | Generative-     |              N/A |               0.365 | 56.1KB | 2025-04-09 | 2025-03-21 | /Users/yi-nungy | This model can be    | PyTorch 2 | Conditiona | CIFAR-10   | 256   | 0.01 | Adam      | 400    | CPU |
|      | CIFAR-10-Cat-Do |                  |                     |        |            |            | eh/PyCharmMiscP | fine-tuned for       |           | lUNet      | Cat Dog    |       |      |           |        |     |
|      | g_latent_autoen |                  |                     |        |            |            | roject/Generati | specific classes     |           |            |            |       |      |           |        |     |
|      | coder_new_struc |                  |                     |        |            |            | ve-             | (e.g., "dog" or      |           | An end-to- |            |       |      |           |        |     |
|      | ture            |                  |                     |        |            |            | CIFAR-10-Cat-Do | "cat") in the        |           | end archit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | g/latent_autoen | CIFAR-10 dataset,    |           | ecture     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | coder_new_struc | enabling it to       |           | that       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | ture.py         | generate high-       |           | learns to  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | quality images with  |           | generate   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | minimal noise. ###   |           | images of  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Data Pipeline and    |           | cat and    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Preprocessing        |           | dog from a |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | #### Dataset         |           | conditiona |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | This CatDog          |           | l autoenco |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Conditional          |           | der.       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Autoencoder is       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | trained on the       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFAR-10 dataset,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | which contains       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 50,000 training      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | images, 10,000 test  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | images split across  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ten classes (cat,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dog, ship, truck,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | bus, horse, bird,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | killer whale, frog,  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and deer). #### Data |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Loader               |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Data is loaded using |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the following data   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | loaders:             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | - Train dataset: `Ca |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | tDogDataset(batch_si |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ze=256)`             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | - Test dataset: `Cat |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | DogDataset(batch_siz |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | e=8)`                |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ### Model            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Architecture         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Conditional        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Autoencoder:**       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 1. Encoder (unet) -  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | A UNet model with    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | input channels 3 and |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | output channels of   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | each class in        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CIFAR-10, where the  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | encoder generates    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | class embeddings for |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditioning during  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruction or    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | diffusion processes. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Classifier - A       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | linear classifier (` |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | SimpleAutoencoder(in |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | _channels=3).to(devi |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ce)`).               |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | SimpleAutoencoder    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (unet) - The base    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | UNet model with      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | input channels 3 and |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | output channels 1    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for generating       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstructions.     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | TimeEmbedding        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (custom) &           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ClassEmbedding       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (custom) - Embedders |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | that map time        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | indices or class     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | labels to a shared   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | latent space, used   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | by the conditional   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | autoencoder's        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | diffusion and        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditioning         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | processes.           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | UNetAttentionBlock   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (module in unet) - A |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | custom module        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | enhancing the base   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | UNet model with      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | attention mechanisms |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for improved         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance.         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ConditionalUNet      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (unet) - A           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | customized           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditional          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | autoencoder using    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the encoder, UNET    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and other modules    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from this            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture. ###    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Training             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Configuration        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | - Optimizer: `torch. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | optim.AdamW(learning |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | _rate=3e-4,          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | weight_decay=0.05)`  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | - Losses:            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Classification       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | losses are           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | calculated using     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | cross entropy        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (`class_loss = F.cro |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ss_entropy(...)`),   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruction loss  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for autoencoder is   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Mean Squared Error   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (MSE) between real   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and reconstructed    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | data. ###            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Visualization        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Artifacts & Output   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Files                |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Training results are |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | saved in `Images     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | folder (cifar_cat_do |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | g_conditional_v5)`   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | on your local        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | machine, containing  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstructed images |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from autoencoder     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | iterations as well   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as the animation     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | files generated      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | during training. 4.  |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  2   | Generative-     |              N/A |               0.424 | 70.0KB | 2025-04-09 | 2025-03-24 | /Users/yi-nungy | * **Training         | PyTorch 2 | Conditiona | CIFAR-10   | 128   | None | None      | 300    | CPU |
|      | CIFAR-10-Cat-Do |                  |                     |        |            |            | eh/PyCharmMiscP | Configuration**:     |           | lDenoiseDi | Cat Dog    |       |      |           |        |     |
|      | g_latent_autoen |                  |                     |        |            |            | roject/Generati |   * Use batch size   |           | ffusion    |            |       |      |           |        |     |
|      | coder_new_struc |                  |                     |        |            |            | ve-             | of 128 for training  |           |            |            |       |      |           |        |     |
|      | ture_vae        |                  |                     |        |            |            | CIFAR-10-Cat-Do | data. * **Train/Test |           | The 'Condi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | g/latent_autoen | Data Loaders**       |           | tionalDeno |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | coder_new_struc |   * Training dataset |           | iseDiffusi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | ture_vae.py     | is loaded using      |           | on' class  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | `DataLoader` with    |           | is         |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | batch_size of 64,    |           | identified |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | shuffling enabled    |           | by its inh |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and num_workers=2    |           | eritance   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for parallel         |           | from       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | loading. Test        |           | Module,    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset has an       |           | along with |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | independent loader   |           | the        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | with batch size=8    |           | presence   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (no shuffle) or 500  |           | of UNetAtt |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | samples. * **Model   |           | entionBloc |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Structure & Training |           | k, SwitchS |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Pipeline**:          |           | equential, |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    1. TimeEmbedding  |           | and Condit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and ClassEmbedding   |           | ionalUNet  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | modules with their   |           | classes.   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dimensions.          |           | This       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | UNetAttentionBlock,  |           | suggests   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | UNetResidualBlock,   |           | the implem |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | SwitchSequential for |           | entation   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | deep learning        |           | combines   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | layers. Noise        |           | elements   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | prediction loss      |           | of         |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | computation occurs   |           | encoder-   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | optionally with      |           | decoder    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | class conditioning   |           | networks   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | enabled. Compute     |           | with       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | class prediction     |           | attention  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | losses with          |           | mechanisms |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classifier-free      |           | and condit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | guidance for each    |           | ional gene |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training iteration   |           | ration.    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | of the AE in         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conjunction with     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | separate optimizers: |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | one for              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruction and   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | another for          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classification. *    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Learning           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Schedule**:          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    1. Create         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | original linear beta |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | schedule for loading |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | checkpoints, blend   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | two beta schedules   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (with given ratio),  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and transition       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | between them using   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | cos() function to    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | adjust learning      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | rates at certain     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | epochs or steps. 2.  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | * **Inference/Predic |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | tion**:              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |   No specific        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | mention of an        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | inference method,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | assuming the trained |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | CUT will output      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | latent codes         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | corresponding to     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | input classes for    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generating outputs   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | based on their prior |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | knowledge.           |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  3   | EncoderDecoder_ |              N/A |               0.804 |  5.6KB | 2025-03-03 | 2025-03-03 | /Users/yi-nungy | **Model Training:**  | PyTorch 2 | EncoderDec | MathDatase | 64    | 5e-0 | Adam      | 50     | GPU |
|      | scriptRNN_LSTM  |                  |                     |        |            |            | eh/PyCharmMiscP | Run the 'train'      |           | oderModel  | t          |       | 4    |           |        |     |
|      |                 |                  |                     |        |            |            | roject/Calculat | function with a      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | ion/Addition/En | suitable learning    |           | The        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | coderDecoder/sc | rate, batch size,    |           | provided   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | riptRNN_LSTM.py | and hardware         |           | model      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | allocation settings. |           | script     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Data               |           | contains   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Preparation:**       |           | an Encoder |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Collect expressions  |           | and a      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from students and    |           | Decoder    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | normalize them to    |           | class,     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ensure similar       |           | both       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | problem complexity   |           | inheriting |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | levels across the    |           | from       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training dataset.    |           | PyTorch's  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Model Selection    |           | Module     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and Output           |           | base       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Artifacts:** The     |           | class. The |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | trained Encoder-     |           | Tokenizer  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Decoder network does |           | class is   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | not output any       |           | used for t |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visual artifacts; it |           | okenizatio |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | saves only the       |           | n of the   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learned parameters   |           | input expr |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in the model's       |           | essions    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | state_dict() during  |           | before     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training phase.      |           | passing    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Additionally, while  |           | them to    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the AST summary      |           | the        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | doesn't show it      |           | Encoder.   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | directly, some       |           | The        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | example output       |           | forward    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | results from the     |           | method of  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | trained model could  |           | these      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | have been saved in   |           | classes    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the "results"        |           | performs   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | directory; you might |           | basic      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | want to inspect this |           | encoder-   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | part as well if      |           | decoder op |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | missing images are   |           | erations.  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | not found within the |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training code        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | itself. The main     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | goal is to train a   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | machine learning     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model that can       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | predict the correct  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | output based on an   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | input expression.    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Data Pipeline and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Preprocessing**      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The dataset consists |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | of math expressions, |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | each tokenized by    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the provided         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | `Tokenizer` class.   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The data is first    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | divided into         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training and testing |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | datasets using the ` |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generate_addition_da |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ta()` function.      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | DataLoader objects   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | are created for both |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the train and test   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | sets with batch      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | sizes set to 64.     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Additionally, a test |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | data loader is       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | created for          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | evaluating the       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model's performance  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | on unseen math       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | expressions. The     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model outputs the    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | top N most probable  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | tokens based on the  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | attention scores     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | calculated by the    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | attention mechanism  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | during the           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | prediction phase.    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Training           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Configuration**      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The training         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | configuration        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | involves an Adam     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | optimizer with a     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning rate of     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 0.0005 for the       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | encoder and decoder  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | parameters, as well  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as an initial        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning rate of     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 0.01 for all other   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model-specific       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | parameters. Make     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | sure you have a      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | valid dataset to     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | tokenize math        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | expressions for      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | arithmetic addition  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | using the            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | `Tokenizer` class.   |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+

```
