### Sample 2

Input:
```
Which models use Unet architectures?
```

Output:

```
<think>
Okay, so I need to figure out which models use Unet architectures based on the provided search results. Let me go through each model one by one.

Starting with Model #1: Generative-Fashion-MNIST_script_unet. The description says it's a U-Net architecture combined with Fashion MNIST denoising features. So that's definitely using U-Net.

Moving to Model #2: Generative-Fashion-MNIST_latent_new_model. The architecture is described as an Autoencoder with Denoising Diffusion, but I don't see any mention of Unet here. It uses classes like SimpleAutoencoder and UNetResidualBlock. Wait, there's a UNetResidualBlock class, which might be part of the U-Net architecture. But the main component is an autoencoder, not U-Net per se.

Model #3: Generative-Fashion-MNIST_latent_new_conditional_model. The description mentions using ConditionalDenoiseDiffusion and ConditionalUNet. So this one definitely uses a U-Net-like structure called ConditionalUNet.
</think>

Based on the analysis of the provided models:

**Models that use Unet architectures:**

1. **Generative-Fashion-MNIST_script_unet**
   - **Architecture**: U-Net
   - **Description**: Combines U-Net with Fashion MNIST denoising features.

2. **Generative-Fashion-MNIST_latent_new_conditional_model**
   - **Architecture**: ConditionalUNet (part of U-Net family)
   - **Description**: Implements a conditional denoising diffusion autoencoder using U-Net-like blocks.

**Summary:** Two models utilize Unet-based architectures: the first explicitly as a U-Net, and the third through its UNet components.

Retrieving and displaying reranked search results:

+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
| Rank | Model ID        | Similarity Score | Similarity Distance |   Size | Created    | Modified   | Path            | Description          | Framework | Arch       | Dataset    | Batch | LR   | Optimizer | Epochs | HW  |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  1   | Generative-     |              N/A |               0.445 | 33.8KB | 2025-03-14 | 2025-03-14 | /Users/yi-nungy | The length of this   | PyTorch 2 | FashionMNI | Fashion    | 128   | 2e-0 | AdamW     | 150    | CPU |
|      | Fashion-MNIST_s |                  |                     |        |            |            | eh/PyCharmMiscP | documentation has    |           | STUNetDeno | MNIST      |       | 4    |           |        |     |
|      | cript_unet      |                  |                     |        |            |            | roject/Generati | been kept concise    |           | iser       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | ve-Fashion-MNIS | but retains all      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | T/script_unet.p | essential            |           | The model  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | y               | information for      |           | is a combi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | understanding and    |           | nation of  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reproducing the      |           | U-Net and  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | implemented machine  |           | Fashion    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning system:     |           | MNIST      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           | denoising  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ---                  |           | features.  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Model Script       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Documentation**      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 1. **Purpose and     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Overview**           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The script is a      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | trained denoising    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generative model     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | using a U-Net        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture with    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | PyTorch. The         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | objective of this    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | codebase is to learn |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the Fashion MNIST    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset by training  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | an image denoising   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | network, enabling it |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | to generate visually |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | realistic Fashion    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | MNIST images without |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | noise. **Data        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Pipeline and         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Preprocessing**      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The data pipeline    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | starts by importing  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | required packages    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (e.g., torch) and    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | loading the Fashion  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | MNIST dataset using  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | datasets and         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transforms from      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | torchvision and      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | DataLoader from      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | torch.utils.data,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | respectively.        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Model              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Architecture**       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The architecture     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | consists of several  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | modules:             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - SelfAttention   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | module with O(n)     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | complexity instead   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | of O(nÂ²). - Forward  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | pass using linear    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | attention mechanism  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for visualization    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | purposes. - A U-Net  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | image denoising      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model, which         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | includes the Fashion |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | MNISTUNetDenoiser    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | class that           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | initializes weights  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | using Xavier         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | initialization and   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | has a forward pass   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | through 256 time     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dimensions before    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | outputting an image. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Training           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Configuration**      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The training process |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | utilizes the         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | following            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | parameters:          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - A device (GPU   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | if available,        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | otherwise CPU) is    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | specified in the     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | script for parallel  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | computation. - The   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model is trained     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | using a FashionMNIST |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | UNetDenoiser class   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | with given           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters such |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as input size,       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | number of classes,   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | patch size, and time |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dimensions. - Set up |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | a GPU-enabled        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | machine for training |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | if available and     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | configure CUDA/cuDNN |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | on the device. -     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Follow model         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | guidelines provided  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in this document by  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | adjusting            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | input dimensions,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | etc., as needed. By  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | following these      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | steps, a junior      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | engineer can fully   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | understand and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | potentially extend   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | this implementation  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for various tasks or |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | improvements within  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the U-Net framework  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | with Fashion MNIST   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset.             |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  2   | Generative-     |              N/A |               0.533 | 43.4KB | 2025-04-09 | 2025-03-16 | /Users/yi-nungy | It consists of two   | PyTorch 2 | Autoencode | Fashion    | 256   | 1e-0 | Adam      | 1000   | GPU |
|      | Fashion-MNIST_l |                  |                     |        |            |            | eh/PyCharmMiscP | main components - an |           | r with     | MNIST      |       | 3    |           |        |     |
|      | atent_new_model |                  |                     |        |            |            | roject/Generati | autoencoder for      |           | Denoising  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | ve-Fashion-MNIS | feature extraction,  |           | Diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | T/latent_new_mo | and a diffusion-     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | del.py          | based denoising      |           | The        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | process that         |           | codebase   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generates new        |           | features a |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | samples with diverse |           | SimpleAuto |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | styles from the      |           | encoder    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learned latent       |           | class,     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | space. This system   |           | which is   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | aims to tackle the   |           | an autoenc |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Fashion MNIST        |           | oder that  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset's            |           | denoise    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | limitations by       |           | input data |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | providing a larger   |           | using a    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | variety of styles in |           | diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generated images, as |           | process. A |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | well as visualizing  |           | dditionall |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and capturing the    |           | y, there's |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | underlying latent    |           | also a Sim |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | space structure. The |           | pleDenoise |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset used is      |           | Diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | FashionMNIST, stored |           | and UNetRe |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | locally at           |           | sidualBloc |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | '/Users/yi-nungyeh/P |           | k classes  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | yCharmMiscProject/Ge |           | within the |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | nerative-Fashion-MNI |           | codebase.  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ST/fashion_mnist_res |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ults'. **Model       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Architecture**       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |                      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 1. **Autoencoder**:  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | An Encoder-Decoder   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture is      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | employed for feature |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | extraction and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generation of new    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | images. The Swish    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | activation function  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | (`SimpleUNet` class  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from                 |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | torch.nn.functional) |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | replaces traditional |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | sigmoid or tanh      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | activations.         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Diffusion Model**: |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | A denoising process  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | is applied using the |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | `SimpleDenoiseDiffus |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ion` module, which   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | applies a diffusion  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model with noise     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | prediction loss      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | calculation. During  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | each epoch, data     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from both 'train'    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and 'test' datasets  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | are used to train    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the autoencoder and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | denoising diffusion  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | process in parallel. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Visualizations like  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | image interpolation  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | between two random   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | samples in the       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | latent space (t-SNE) |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and tracking         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | progress during      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training epochs help |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | assess whether the   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | autoencoder is       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning meaningful  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | features for style   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transfer. The        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | trained model's      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance on       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Fashion MNIST        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | datasets is          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | evaluated by         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generating new       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | images based on      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learned styles using |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the autoencoder,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | which can be         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualized via       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | matplotlib and saved |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | as test set results  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in the 'fashion_mnis |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | t_results/images'    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | folder. For          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | extension, consider  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | experimenting with   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architectures,       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | learning rate        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | schedules,           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | optimization         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | strategies, and      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | regularization       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | techniques. This     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | could involve        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | adjusting model      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters to   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | achieve better       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance or       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | exploring new data   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | augmentation methods |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for improved style   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transfer accuracy.   |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+
|  3   | Generative-     |              N/A |               0.544 | 47.7KB | 2025-04-09 | 2025-03-17 | /Users/yi-nungy | Dataset              | PyTorch 2 | Conditiona | Fashion    | 256   | 1e-0 | Adam      | 100    | CPU |
|      | Fashion-MNIST_l |                  |                     |        |            |            | eh/PyCharmMiscP | transformations      |           | lDenoiseDi | MNIST      |       | 3    |           |        |     |
|      | atent_new_condi |                  |                     |        |            |            | roject/Generati | include              |           | ffusion    |            |       |      |           |        |     |
|      | tional_model    |                  |                     |        |            |            | ve-Fashion-MNIS | normalization,       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | T/latent_new_co | augmentation         |           | The        |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | nditional_model | (rotation and        |           | codebase   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            | .py             | horizontal           |           | is impleme |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | flipping), and color |           | nting a co |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | manipulation to      |           | nditional  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | improve learning     |           | denoising  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ability of the       |           | diffusion  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model. **Model       |           | autoencode |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Architecture**       |           | r for      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - The autoencoder |           | Fashion    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | consists of a simple |           | MNIST      |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | encoder-decoder      |           | dataset.   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | structure with three |           | The archit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | convolutional layers |           | ecture     |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | followed by two      |           | comprises  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transposed           |           | several    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | convolutional layers |           | modules    |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | in the decoder for   |           | like       |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | image                |           | Encoder,   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruction. It   |           | Decoder, U |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | uses 'BatchNorm' and |           | NetAttenti |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | LeakyReLU as its     |           | onBlock,   |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | activation function, |           | etc., and  |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and Swish is used as |           | uses Condi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | another activation   |           | tionalUNet |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | function. **Training |           | and Condit |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Configuration**      |           | ionalDenoi |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - The learning    |           | seDiffusio |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | rate is set to 0.001 |           | n classes. |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | using AdamW          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | optimizer with       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | weight decay of      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | 0.0005 for unet and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ConditionalDenoiseDi |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | ffusion models.      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Evaluation and     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Testing              |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Methodology**        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - The training    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | progress is          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualized using     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | matplotlib with loss |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | curves and metric    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | tracking plots.      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | After each epoch,    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | autoencoder          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generates samples    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | from pure noise,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditioned on a     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | target class, and    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | compares them to     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | original images in   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the dataset to       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | calculate model      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | performance metrics  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | such as accuracy and |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reconstruction       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | error.               |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | **Visualization and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | Output Artifacts**   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 |    - The code        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | utilizes matplotlib  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for data             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | visualization        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | purposes. After      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | completion of        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | training, t-SNE is   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | used to visualize    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the latent space of  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the autoencoder and  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | generate GIF         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | animations showing   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the diffusion        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | process with         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different target     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | classes. The         |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | provided code can    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | serve as a starting  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | point for further    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | extensions or        |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | improvements such as |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | changing             |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | architecture, using  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | different loss       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | functions, exploring |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | other datasets, or   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | adjusting            |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | hyperparameters. -   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | The architecture     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | description covers   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | all layers and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | transformations of   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | the autoencoder      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | model, including     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditional          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | conditioning blocks. |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | - Training and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | evaluation           |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | procedures are       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | completely and       |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | correctly documented |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | for both unet and Co |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | nditionalDenoiseDiff |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | usion models. - This |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | documentation can    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | serve as a starting  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | point for a junior   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | engineer to          |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | reproduce this model |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | with no further      |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | guidance needed,     |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | assuming they have   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | access to necessary  |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | resources (PyTorch   |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | and Fashion MNIST    |           |            |            |       |      |           |        |     |
|      |                 |                  |                     |        |            |            |                 | dataset).            |           |            |            |       |      |           |        |     |
+------+-----------------+------------------+---------------------+--------+------------+------------+-----------------+----------------------+-----------+------------+------------+-------+------+-----------+--------+-----+

```
