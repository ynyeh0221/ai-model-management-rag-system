# AI Model Management RAG System Capabilities Demo

## Overview

ModelSearch AI is a powerful model search and retrieval system designed for machine learning researchers and engineers. The system enables intelligent searching across large model repositories, retrieving model information based on various criteria and providing structured outputs.

## Core Capabilities

### 1. Model Attribute-Based Retrieval

The system supports model retrieval based on the following attributes:

- **Architecture types**: CNN, RNN, UNet, etc.
- **Frameworks**: PyTorch, etc.
- **Datasets**: MNIST, Fashion-MNIST, Oxford Flower, etc.
- **Time ranges**: Filter by creation or modification date
- **Specific applications**: Such as game AI (2048 game)

The query system supports both inclusion and exclusion logic, meaning users can use keywords like "not" and "without" to refine searches effectively.

**Example queries:**
```
Which models use Unet architectures?
Please find models created in April and using CelebA.
List all seq2seq models that use attention mechanisms.
Show me models trained on the MNIST dataset using autoencoder.
Show me models using autoencoder but not trained on MNIST dataset.
Please find models created in March 2025 and using RNN.
Please find models not using RNN, created in March 2025.
```

### 2. Specific Model Details Retrieval

The system provides detailed information about specific models, including:

- Model ID
- File size
- Creation date
- Last modification date
- Framework information
- Architecture details
- Training dataset
- Training configuration (batch size, learning rate, optimizer, etc.)
- Full description

**Example query:**
```
What DQN (Deep Q-Learning) agent did I try for the game called 2048?
Do I have models which were trained on animal images?
```

### 3. Model Details Comparison

The system allows users to compare detailed metadata between two or more models, enabling a clear understanding of architectural differences, training configurations, and performance metrics. This feature is essential for both researchers and engineers who need to evaluate model evolution, performance trade-offs, or dataset shifts.

**Capabilities:**
- Compare **architectures** (type, layers, hidden sizes, attention heads, parameters).
- Contrast **performance metrics** such as accuracy, loss, and perplexity.
- Analyze **training setups**, including batch size, optimizer, learning rate, hardware usage, and epochs.
- Examine **dataset usage** and framework details.
- Identify **relative improvements** across models (e.g., accuracy gains per parameter).
- Automatically generates structured comparisons such as best/worst rankings and pairwise performance gaps.

**Supported Comparison Types:**
- **Direct model ID comparison**: Compares multiple models by specifying their model IDs.
- **Cohort-based comparison**: Allows free-text cohort comparison, where each cohort is defined by a natural language query.

**Example queries:**
```
Please compare differences in architecture and dataset between model id model_123 and model id model_456.
Compare the diffusion models trained on CIFAR-10 and MNIST.
```

### 4. Generated Image Retrieval

The system supports retrieving images generated by specific models, providing detailed metadata:

- Image ID
- Parent model ID
- Creation date
- Last modification date
- Training epoch
- Image path

**Example query:**
```
please find images of model id oxford_flowers_conditional
```

### 5. Dataset Exploration

The system can explore various models trained on specific datasets:

**Example query:**
```
What diffusion models have been trained on the Oxford Flower dataset?
Show me models trained on the MNIST dataset using autoencoder.
```

## Output Formats

The system provides several formatted outputs:

1. **Tabular format**: Structured display of model information, including similarity scores, file sizes, creation dates, etc.
2. **Detailed descriptions**: Comprehensive information about model architecture, training parameters, and performance metrics
3. **Image listings**: Display of model-generated images and related metadata

## Use Case Scenarios

### Researcher Use Cases

- Find recent implementations of specific architectures
- Compare different models trained on the same dataset
- Track model training progress and results

### Engineer Use Cases

- Find pre-trained models suitable for specific applications
- Retrieve sample images generated by models
- Access model training configuration details to reproduce experiments

## Limitations and Notes

- Thumbnail display is not supported in CLI mode
- Image-to-image similarity search is not available in CLI mode
- Some complex semantic queries may require specific technical terminology for best results
- Search results may sometimes be truncated in responses

## Sameple Inputs/Outputs

### CLI

#### Model - Deepseek-llm 7b

Sample 1: [What diffusion models have been trained on the Oxford Flower dataset?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_1.md)

Sample 2: [Which models use Unet architectures?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_2.md)

Sample 3: [Can you please compare differences in architecture between my diffusion models on CIFAR-10 and MNIST?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_3.md)

Sample 4: [What DQN (Deep Q-Learning) agent did I try for the game called 2048?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_4.md)

Sample 5: [please compare architecture and training config of model id Generative-Fashion-MNIST_latent_new_model and model id Gnerative-CIFAR-10-GAN_v1](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_5.md)

Sample 6: [Please find models created in April 2025 and using CelebA.](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_6.md)

Sample 7: [Show me models trained on the MNIST dataset using autoencoder.](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-llm/sample_input_output_7.md)

#### Model - Deepseek-r1 7b

Sample 1: [What diffusion models have been trained on the Oxford Flower dataset?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_1.md)

Sample 2: [Which models use Unet architectures?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_2.md)

Sample 3: [Can you please compare differences in architecture between my diffusion models on CIFAR-10 and MNIST?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_3.md)

Sample 4: [What DQN (Deep Q-Learning) agent did I try for the game called 2048?](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_4.md)

Sample 5: [please compare architecture and training config of model id Generative-Fashion-MNIST_latent_new_model and model id Gnerative-CIFAR-10-GAN_v1](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_5.md)

Sample 6: [Please find models created in April 2025 and using CelebA.](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_6.md)

Sample 7: [Show me models trained on the MNIST dataset using autoencoder.](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_7.md)

Sample 8: [Show me models using autoencoder but not trained on MNIST dataset](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_8.md)

Sample 9: [Please find models created in March 2025 and using RNN.](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_9.md)

Sample 10: [Please find models not using RNN, created in March 2025.](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/deepseek-r1/sample_input_output_10.md)

### Streamlit

#### Model - Deepseek-r1 7b

##### Query

![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20query%201.png)

![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20query%202.png)

![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20query%203.png)

![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20query%204.png)

![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20query%205.png)

![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20query%206.png)

##### List-models
![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20list-models.png)

##### Help
![](https://github.com/ynyeh0221/model-insight-rag/blob/main/demo/screenshot/streamlit%20help.png)

